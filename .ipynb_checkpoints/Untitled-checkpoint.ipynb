{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c365f40-e190-4812-8409-f351ad480190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anaconda\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ce86d4-3134-489d-86ce-077e6b55013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Classification complete! Sample results:\n",
      "                                            Feedback        Category\n",
      "0        The syllabus isn't being completed on time.       Academics\n",
      "1         Wi-Fi doesn't work properly in the hostel.        Facility\n",
      "2  The admin office is delaying scholarship appro...  Administration\n",
      "3    Professors don't respond to doubts after class.  Administration\n",
      "4     There are not enough fans in the lecture hall.      Facilities\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def classify_feedback_flan_t5(feedback):\n",
    "    prompt = f\"\"\"\n",
    "Classify the following student feedback into one of these categories:\n",
    "Academics, Facilities, Administration\n",
    "\n",
    "Feedback: \"The professor skips too many lectures.\"\n",
    "Category: Academics\n",
    "\n",
    "Feedback: \"Wi-Fi in the hostel is very slow.\"\n",
    "Category: Facilities\n",
    "\n",
    "Feedback: \"The admin office is not replying to my scholarship emails.\"\n",
    "Category: Administration\n",
    "\n",
    "Feedback: \"{feedback}\"\n",
    "Category:\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "    category = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return category.strip()\n",
    "\n",
    "\n",
    "# Load your feedback CSV file\n",
    "df = pd.read_csv(\"feedback.csv\")\n",
    "\n",
    "# Apply classification to each feedback entry\n",
    "df['Category'] = df['Feedback'].apply(classify_feedback_flan_t5)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df.to_csv(\"classified_feedback.csv\", index=False)\n",
    "\n",
    "print(\"Classification complete! Sample results:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933089bb-c96d-43b8-97d0-b45488853a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
